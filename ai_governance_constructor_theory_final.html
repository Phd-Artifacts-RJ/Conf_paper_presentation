<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Constructor Theory - AI Governance: Complete Framework</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            background: linear-gradient(135deg, #0d47a1 0%, #1565c0 100%);
            padding: 20px;
            margin: 0;
        }
        .container {
            max-width: 1800px;
            margin: 0 auto;
            background: white;
            border-radius: 15px;
            padding: 40px;
            box-shadow: 0 20px 100px rgba(0,0,0,0.5);
        }
        h1 {
            text-align: center;
            color: #0d47a1;
            margin-bottom: 10px;
            font-size: 2.8em;
        }
        .subtitle {
            text-align: center;
            color: #555;
            margin-bottom: 15px;
            font-size: 1.15em;
            font-style: italic;
        }
        .story-context {
            background: linear-gradient(135deg, #f3e5f5 0%, #e1f5fe 100%);
            padding: 25px;
            border-radius: 10px;
            border-left: 5px solid #0d47a1;
            margin-bottom: 40px;
            line-height: 1.7;
        }
        .story-context strong { color: #0d47a1; }
        .revision-highlight {
            background: #fff3e0;
            border-left: 5px solid #ff6f00;
            padding: 15px;
            margin-bottom: 30px;
            border-radius: 8px;
        }
        .revision-highlight strong { color: #ff6f00; }
        .new-addition {
            background: #e8f5e9;
            border-left: 5px solid #2e7d32;
            padding: 15px;
            margin-bottom: 30px;
            border-radius: 8px;
        }
        .new-addition strong { color: #2e7d32; }
        .main-diagram {
            background: #f5f5f5;
            border: 3px solid #0d47a1;
            border-radius: 10px;
            padding: 30px;
            margin-bottom: 40px;
            overflow-x: auto;
        }
        svg {
            display: block;
            margin: 0 auto;
            min-width: 100%;
        }
        .section {
            margin-bottom: 40px;
            background: #f8f9fa;
            padding: 25px;
            border-radius: 10px;
            border-left: 5px solid #0d47a1;
        }
        .section h2 {
            color: #0d47a1;
            margin-top: 0;
            font-size: 1.6em;
        }
        .section.new-section {
            border-left: 5px solid #2e7d32;
            background: linear-gradient(135deg, #f1f8e9 0%, #f8f9fa 100%);
        }
        .section.new-section h2 { color: #2e7d32; }
        .component {
            background: white;
            padding: 18px;
            margin: 15px 0;
            border-radius: 8px;
            border-left: 4px solid #1565c0;
            box-shadow: 0 2px 8px rgba(0,0,0,0.05);
        }
        .component-title {
            font-weight: bold;
            color: #0d47a1;
            font-size: 1.15em;
            margin-bottom: 10px;
        }
        .component-content {
            color: #333;
            line-height: 1.7;
        }
        .notation {
            font-family: 'Courier New', monospace;
            background: #e3f2fd;
            padding: 8px 12px;
            border-radius: 4px;
            color: #0d47a1;
            font-weight: bold;
            display: inline-block;
            margin: 5px 0;
        }
        .notation.green {
            background: #e8f5e9;
            color: #2e7d32;
        }
        .possible { background: #e8f5e9; border-left-color: #388e3c; }
        .impossible { background: #ffebee; border-left-color: #d32f2f; }
        .fragile { background: #fff3e0; border-left-color: #f57c00; }
        .selection { background: #f3e5f5; border-left-color: #7b1fa2; }
        .neutral { background: #f3e5f5; border-left-color: #7b1fa2; }
        .stability { background: #e8f5e9; border-left-color: #2e7d32; }
        .task-hierarchy {
            background: white;
            border: 2px solid #0d47a1;
            padding: 20px;
            border-radius: 8px;
            margin: 15px 0;
        }
        .hierarchy-level {
            margin: 15px 0;
            padding: 15px;
            background: #f5f5f5;
            border-left: 4px solid #0d47a1;
            border-radius: 4px;
        }
        .hierarchy-level.new-level {
            background: #e8f5e9;
            border-left-color: #2e7d32;
        }
        .hierarchy-level-title {
            font-weight: bold;
            color: #0d47a1;
            font-size: 1.05em;
            margin-bottom: 8px;
        }
        .hierarchy-level.new-level .hierarchy-level-title { color: #2e7d32; }
        .hierarchy-level-content {
            color: #555;
            font-size: 0.95em;
        }
        .flow-diagram {
            background: white;
            padding: 20px;
            border-radius: 8px;
            border: 2px solid #e0e0e0;
            margin: 15px 0;
        }
        .flow-box {
            display: inline-block;
            background: linear-gradient(135deg, #1565c0 0%, #0d47a1 100%);
            color: white;
            padding: 15px 20px;
            border-radius: 6px;
            margin: 10px 5px;
            font-weight: 500;
            min-width: 140px;
            text-align: center;
        }
        .flow-box.secondary { background: linear-gradient(135deg, #9fa8da 0%, #7986cb 100%); }
        .flow-box.input { background: linear-gradient(135deg, #4caf50 0%, #388e3c 100%); }
        .flow-box.output { background: linear-gradient(135deg, #ff7043 0%, #e64a19 100%); }
        .flow-box.decision { background: linear-gradient(135deg, #fbc02d 0%, #f57f17 100%); color: #333; }
        .flow-box.selection { background: linear-gradient(135deg, #7b1fa2 0%, #4a148c 100%); }
        .flow-box.council { background: linear-gradient(135deg, #2e7d32 0%, #1b5e20 100%); }
        .flow-arrow {
            display: inline-block;
            color: #0d47a1;
            margin: 0 8px;
            font-weight: bold;
            font-size: 1.2em;
        }
        .comparison-grid {
            display: grid;
            grid-template-columns: repeat(auto-fit, minmax(350px, 1fr));
            gap: 20px;
            margin: 20px 0;
        }
        .comparison-card {
            background: white;
            border: 2px solid #ddd;
            border-radius: 8px;
            padding: 20px;
        }
        .comparison-card h4 {
            margin-top: 0;
            color: #0d47a1;
            border-bottom: 2px solid #1565c0;
            padding-bottom: 10px;
        }
        .comparison-card ul { margin: 10px 0; padding-left: 20px; }
        .comparison-card li { margin: 8px 0; color: #555; }
        .key-principle {
            background: linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%);
            border-left: 5px solid #0d47a1;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            font-size: 1.05em;
            line-height: 1.8;
        }
        .key-principle strong { color: #0d47a1; }
        .key-principle.new-principle {
            background: linear-gradient(135deg, #e8f5e9 0%, #f1f8e9 100%);
            border-left-color: #2e7d32;
        }
        .key-principle.new-principle strong { color: #2e7d32; }
        .key-insight {
            background: linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%);
            border-left: 5px solid #0d47a1;
            padding: 20px;
            border-radius: 8px;
            margin: 20px 0;
            font-size: 1.05em;
            line-height: 1.8;
        }
        .key-insight strong { color: #0d47a1; }
        .story-element {
            background: #f3e5f5;
            padding: 15px;
            border-radius: 6px;
            margin: 10px 0;
            border-left: 4px solid #7b1fa2;
        }
        .story-element strong { color: #7b1fa2; }
        .story-element.new-story {
            background: #e8f5e9;
            border-left-color: #2e7d32;
        }
        .story-element.new-story strong { color: #2e7d32; }
        .formula-box {
            background: #263238;
            color: #aed581;
            padding: 15px 20px;
            border-radius: 8px;
            font-family: 'Courier New', monospace;
            margin: 15px 0;
            overflow-x: auto;
        }
        .formula-box .formula-title {
            color: #81d4fa;
            font-weight: bold;
            margin-bottom: 10px;
        }
        table {
            width: 100%;
            border-collapse: collapse;
            margin: 15px 0;
            background: white;
        }
        th, td {
            border: 1px solid #ddd;
            padding: 12px;
            text-align: left;
        }
        th {
            background: #0d47a1;
            color: white;
            font-weight: bold;
        }
        tr:nth-child(even) { background: #f5f5f5; }
        tr.new-row { background: #e8f5e9 !important; }
        @media (max-width: 1024px) {
            .comparison-grid { grid-template-columns: 1fr; }
            h1 { font-size: 2em; }
            .container { padding: 20px; }
        }
        .highlight {
            background: #fff9c4;
            padding: 2px 6px;
            border-radius: 3px;
            font-weight: 500;
        }
        .highlight-green {
            background: #c8e6c9;
            padding: 2px 6px;
            border-radius: 3px;
            font-weight: 500;
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>üè∞ Constructor Theory: AI Governance Framework</h1>
        <p class="subtitle">A Complete Constructor-Theoretic Framework for Kingdom Gate Decision-Making</p>
        <p class="subtitle" style="font-size: 0.95em; color: #777;">Incorporating Constructor Selection, Feature Selection Stability (SSUMP), and the AUC Criterion</p>
        
        <div class="story-context">
            <strong>Story Context:</strong> A magical kingdom faces a critical challenge. At its gate, a decision must be made about each traveler: admit, reject, or defer. 
            The kingdom has access to multiple magical books (competing predictive models) that can assess risk. But prediction alone is not enough. The kingdom needs to understand WHY decisions are made, 
            whether those explanations are reliable, and whether the entire system of governance is sound. Through constructor theory, we see that this is not a problem of combining tools, 
            but of understanding which tasks are possible, which are impossible, and what constraints enable trustworthy decision-making.
        </div>
        
        <div class="revision-highlight">
            <strong>Core Framework Principles:</strong><br><br>
            ‚úì Magical Book is a <strong>family of competing constructors</strong> (not a single constructor)<br>
            ‚úì King's primary task is <strong>constructor selection</strong> (not just prediction)<br>
            ‚úì Selection criterion is explicitly the <strong>ordering task</strong> (ranking danger correctly)<br>
            ‚úì <strong>AUC</strong> quantifies the ordering task's robustness<br>
            ‚úì Other metrics inform understanding but do NOT determine selection<br>
            ‚úì Prediction reliability ‚â† Explanation possibility (sharp distinction maintained)<br>
            ‚úì Explanation is a <strong>separate task</strong> whose possibility must be demonstrated separately<br>
            ‚úì <strong>Principled abstention</strong> when justification is impossible
        </div>
        
        <div class="new-addition">
            <strong>üÜï New Addition: The Council of Methods & SSUMP Principle</strong><br><br>
            ‚úì Feature selection is itself a <strong>task requiring a dedicated constructor</strong><br>
            ‚úì The <strong>Council of Methods</strong> aggregates feature rankings from Forest Watcher + Straight-Line Scribe<br>
            ‚úì <strong>SSUMP</strong> (Selection Stability Under Methodological Perturbation) ensures consistent feature selection<br>
            ‚úì Stability is measured via <strong>rank correlation</strong> (Spearman's œÅ ‚â• 0.7) across bootstrap perturbations<br>
            ‚úì The aggregation rule (<strong>Stability-Weighted Intersection</strong>) is <strong>institutionally fixed</strong> to prevent infinite regress
        </div>

        <!-- MAIN SYSTEM DIAGRAM -->
        <div class="main-diagram">
            <h2 style="text-align: center; color: #0d47a1; margin-top: 0;">Complete Governance System Architecture</h2>
            <svg width="100%" height="1200" viewBox="0 0 1400 1200" preserveAspectRatio="xMidYMid meet">
                <!-- Background -->
                <rect width="1400" height="1200" fill="#fafafa"/>
                
                <!-- Title -->
                <text x="700" y="40" text-anchor="middle" font-size="24" font-weight="bold" fill="#0d47a1">
                    AI Governance: Task Hierarchy, Constructor Selection, and Constraint Architecture
                </text>
                
                <!-- LEVEL 0: INSTITUTIONAL CONSTRAINT -->
                <rect x="100" y="70" width="1200" height="90" fill="#fff3e0" stroke="#e65100" stroke-width="3" rx="8"/>
                <text x="700" y="100" text-anchor="middle" font-weight="bold" font-size="16" fill="#e65100">LEVEL 0: INSTITUTIONAL CONSTRAINT</text>
                <text x="700" y="125" text-anchor="middle" font-size="12" fill="#333">Book of Trusted Traits: Defines which explanations are permitted</text>
                <text x="700" y="145" text-anchor="middle" font-size="12" fill="#333">Constraint: Only explanations using stable, reliable features are allowed</text>
                
                <!-- Arrow down -->
                <path d="M 700 160 L 700 185" stroke="#0d47a1" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                
                <!-- LEVEL 1: CONSTRUCTOR SELECTION -->
                <rect x="100" y="190" width="1200" height="110" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="3" rx="8"/>
                <text x="700" y="220" text-anchor="middle" font-weight="bold" font-size="16" fill="#7b1fa2">LEVEL 1: CONSTRUCTOR SELECTION TASK</text>
                <text x="700" y="245" text-anchor="middle" font-size="12" fill="#333">Input: Family of competing constructors (magical books from multiple advisers)</text>
                <text x="700" y="270" text-anchor="middle" font-size="12" fill="#333">Criterion: Which constructor most reliably ranks dangerous travelers above safe ones? (Ordering Task)</text>
                <text x="700" y="290" text-anchor="middle" font-size="11" fill="#555">Metric: AUC (Area Under ROC Curve) ‚Üí Output: Selected constructor deployed at gate</text>
                
                <!-- Arrow down -->
                <path d="M 700 300 L 700 325" stroke="#0d47a1" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                
                <!-- LEVEL 2: GOVERNANCE DECISION -->
                <rect x="100" y="330" width="1200" height="100" fill="#e3f2fd" stroke="#0d47a1" stroke-width="3" rx="8"/>
                <text x="700" y="355" text-anchor="middle" font-weight="bold" font-size="16" fill="#0d47a1">LEVEL 2: META-TASK (Governance)</text>
                <text x="700" y="380" text-anchor="middle" font-size="12" fill="#333">Input: Traveler state, Prediction (from selected constructor), Explanation, Sanity check results</text>
                <text x="700" y="405" text-anchor="middle" font-size="12" fill="#333">Output: Decision (Accept, Review, Abstain)</text>
                <text x="700" y="422" text-anchor="middle" font-size="11" fill="#555">Task: Decide whether the decision task itself is admissible</text>
                
                <!-- Arrows down to three parallel tasks -->
                <path d="M 350 430 L 350 470" stroke="#0d47a1" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                <path d="M 700 430 L 700 470" stroke="#0d47a1" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                <path d="M 1050 430 L 1050 470" stroke="#0d47a1" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                
                <!-- LEVEL 3A: PREDICTION TASK -->
                <rect x="150" y="470" width="400" height="120" fill="#e8f5e9" stroke="#388e3c" stroke-width="2" rx="8"/>
                <text x="350" y="495" text-anchor="middle" font-weight="bold" font-size="14" fill="#388e3c">TASK 3A: PREDICTION</text>
                <text x="350" y="520" text-anchor="middle" font-size="11" fill="#333">Input: Traveler attributes (high-dim)</text>
                <text x="350" y="540" text-anchor="middle" font-size="11" fill="#333">Output: Risk scalar (0-1)</text>
                <text x="350" y="560" text-anchor="middle" font-size="11" fill="#333">Status: ‚úì POSSIBLE (proven by AUC selection)</text>
                <text x="350" y="578" text-anchor="middle" font-size="10" fill="#555">Constructor: Winning Magical Book</text>
                
                <!-- LEVEL 3B: EXPLANATION TASK -->
                <rect x="550" y="470" width="400" height="120" fill="#fff3e0" stroke="#f57c00" stroke-width="2" rx="8"/>
                <text x="750" y="495" text-anchor="middle" font-weight="bold" font-size="14" fill="#f57c00">TASK 3B: EXPLANATION</text>
                <text x="750" y="520" text-anchor="middle" font-size="11" fill="#333">Input: Risk prediction</text>
                <text x="750" y="540" text-anchor="middle" font-size="11" fill="#333">Output: Attribution over features (SHAP)</text>
                <text x="750" y="560" text-anchor="middle" font-size="11" fill="#333">Status: ‚úì POSSIBLE BUT FRAGILE</text>
                <text x="750" y="578" text-anchor="middle" font-size="10" fill="#555">Constructor: Explainer Lantern (SHAP)</text>
                
                <!-- LEVEL 3C: SANITY CHECK TASK -->
                <rect x="950" y="470" width="400" height="120" fill="#ffebee" stroke="#d32f2f" stroke-width="2" rx="8"/>
                <text x="1150" y="495" text-anchor="middle" font-weight="bold" font-size="14" fill="#d32f2f">TASK 3C: SANITY CHECK</text>
                <text x="1150" y="520" text-anchor="middle" font-size="11" fill="#333">Input: Model + Explanation pair</text>
                <text x="1150" y="540" text-anchor="middle" font-size="11" fill="#333">Output: Reliability judgment (Sanity ratio)</text>
                <text x="1150" y="560" text-anchor="middle" font-size="11" fill="#333">Status: ‚úì POSSIBLE AND RIGOROUS</text>
                <text x="1150" y="578" text-anchor="middle" font-size="10" fill="#555">Constructor: Trial of Sanity test</text>
                
                <!-- Arrows down -->
                <path d="M 350 590 L 350 640" stroke="#0d47a1" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                <path d="M 750 590 L 750 640" stroke="#0d47a1" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                <path d="M 1150 590 L 1150 640" stroke="#0d47a1" stroke-width="2" fill="none" marker-end="url(#arrowhead)"/>
                
                <!-- LEVEL 4A: FEATURE STABILIZATION -->
                <rect x="150" y="640" width="400" height="110" fill="#f3e5f5" stroke="#7b1fa2" stroke-width="2" rx="8"/>
                <text x="350" y="665" text-anchor="middle" font-weight="bold" font-size="13" fill="#7b1fa2">SUBTASK 4A: Feature Stabilization</text>
                <text x="350" y="690" text-anchor="middle" font-size="10" fill="#333">Forest Watcher: Nonlinear features</text>
                <text x="350" y="708" text-anchor="middle" font-size="10" fill="#333">Straight-Line Scribe: Linear features</text>
                <text x="350" y="726" text-anchor="middle" font-size="10" fill="#555">Joint output: Book of Trusted Traits</text>
                
                <!-- LEVEL 4B: CONSTRAINT ENCODING -->
                <rect x="550" y="640" width="400" height="110" fill="#e8eaf6" stroke="#5c6bc0" stroke-width="2" rx="8"/>
                <text x="750" y="665" text-anchor="middle" font-weight="bold" font-size="13" fill="#5c6bc0">SUBTASK 4B: Constraint Enforcement</text>
                <text x="750" y="690" text-anchor="middle" font-size="10" fill="#333">Book of Trusted Traits</text>
                <text x="750" y="708" text-anchor="middle" font-size="10" fill="#333">Forbids unreliable explanations</text>
                <text x="750" y="726" text-anchor="middle" font-size="10" fill="#555">Makes impossible tasks that violate constraints</text>
                
                <!-- LEVEL 4C: COUNTERFACTUAL GENERATION -->
                <rect x="950" y="640" width="400" height="110" fill="#e0f2f1" stroke="#00695c" stroke-width="2" rx="8"/>
                <text x="1150" y="665" text-anchor="middle" font-weight="bold" font-size="13" fill="#00695c">SUBTASK 4C: Counterfactual Task</text>
                <text x="1150" y="690" text-anchor="middle" font-size="10" fill="#333">Input: Current traveler state</text>
                <text x="1150" y="708" text-anchor="middle" font-size="10" fill="#333">Output: Nearby state with different outcome</text>
                <text x="1150" y="726" text-anchor="middle" font-size="10" fill="#555">Constraint: Only feasible transformations</text>
                
                <!-- CRITICAL DISTINCTION BOX -->
                <rect x="150" y="790" width="1100" height="70" fill="#ffe0b2" stroke="#e65100" stroke-width="2" rx="8"/>
                <text x="700" y="815" text-anchor="middle" font-weight="bold" font-size="13" fill="#e65100">CRITICAL DISTINCTION (Constructor Theory)</text>
                <text x="700" y="840" text-anchor="middle" font-size="12" fill="#333">Prediction Constructor is Reliable ‚â† Explanation Constructor Exists</text>
                <text x="700" y="855" text-anchor="middle" font-size="11" fill="#555">AUC measures prediction ordering robustness. It says NOTHING about explanation validity.</text>
                
                <!-- Bottom box: Central principle -->
                <rect x="150" y="880" width="1100" height="90" fill="#e3f2fd" stroke="#0d47a1" stroke-width="3" rx="8"/>
                <text x="700" y="910" text-anchor="middle" font-weight="bold" font-size="14" fill="#0d47a1">CENTRAL PRINCIPLE: Task Hierarchy and Constraint Propagation</text>
                <text x="700" y="935" text-anchor="middle" font-size="12" fill="#333">Lower-level tasks (prediction, explanation) are only performed if higher-level task (governance) determines it is admissible.</text>
                <text x="700" y="955" text-anchor="middle" font-size="12" fill="#333">Constraints flow downward: Institutional constraints limit which tasks can be constructed.</text>
                
                <!-- Example flow -->
                <text x="150" y="1005" font-size="13" font-weight="bold" fill="#0d47a1">Decision Flow Example:</text>
                
                <rect x="150" y="1020" width="1100" height="150" fill="white" stroke="#ddd" stroke-width="1" rx="6"/>
                
                <text x="170" y="1045" font-size="11" font-weight="bold" fill="#333">1. CONSTRUCTOR SELECTION:</text>
                <text x="170" y="1062" font-size="10" fill="#555">   Compare all magical books via AUC. Select the one that most reliably orders dangerous above safe.</text>
                
                <text x="170" y="1085" font-size="11" font-weight="bold" fill="#333">2. GOVERNANCE CHECK:</text>
                <text x="170" y="1102" font-size="10" fill="#555">   Can we make a justified decision? Check: Is prediction possible? Is explanation possible? Does sanity check pass?</text>
                
                <text x="170" y="1125" font-size="11" font-weight="bold" fill="#333">3. IF SANITY CHECK FAILS:</text>
                <text x="170" y="1142" font-size="10" fill="#555">   Explanation constructor becomes unreliable ‚Üí Task becomes impossible ‚Üí Governance decision: ABSTAIN</text>
                
                <text x="170" y="1165" font-size="11" font-weight="bold" fill="#333">4. IF ALL SUCCEED:</text>
                <text x="750" y="1165" font-size="10" fill="#555">   Governance task outputs: ACCEPT with confidence</text>
                
                <!-- Arrow definitions -->
                <defs>
                    <marker id="arrowhead" markerWidth="10" markerHeight="10" refX="9" refY="3" orient="auto">
                        <polygon points="0 0, 10 3, 0 6" fill="#0d47a1"/>
                    </marker>
                </defs>
            </svg>
        </div>
        
        <!-- SECTION 1: THE GATE AND GUARDS -->
        <div class="section">
            <h2>üö™ 1. The Kingdom Gate & Guards (Task Boundary)</h2>
            
            <div class="story-element">
                <strong>Story Element:</strong> The gate marks the boundary where transformations occur. Guards apply fixed decision rules but cannot assess whether those rules should be applied.
            </div>
            
            <div class="component">
                <div class="component-title">Gate as Task Boundary, Guards as Simple Constructors</div>
                <div class="component-content">
                    <strong>The Gate (Task Boundary):</strong><br>
                    <span class="notation">T_gate = {traveler_attributes ‚ü∂ decision_state (admit, reject, defer)}</span><br><br>
                    
                    The gate is not a location but a task boundary. It transforms an incoming traveler‚Äîrepresented as an information substrate containing observable attributes‚Äîinto one of three outcome states. This transformation is constrained by institutional rules, data limitations, and epistemic constraints.<br><br>
                    
                    <strong>The Guards (Simple Constructors):</strong><br>
                    <span class="notation">T_guard = {risk_scalar ‚ü∂ action_state (via threshold)}</span><br><br>
                    
                    <strong>Properties of guard constructors:</strong><br>
                    ‚úì Can reliably apply fixed transformation rule repeatedly<br>
                    ‚úì Map scalar risk to action via threshold<br>
                    ‚úì Maintain constructor stability (no degradation)<br><br>
                    
                    <strong>What guards CANNOT do:</strong><br>
                    ‚úó Test hypotheses<br>
                    ‚úó Compare alternatives<br>
                    ‚úó Generate new knowledge<br>
                    ‚úó Assess whether the decision task ought to be performed<br><br>
                    
                    <strong>Constructor-theoretic insight:</strong> Guards can reliably perform the decision task once a risk state is provided, but they cannot assess the admissibility of the decision task itself. That assessment requires higher-level meta-constructors (governance).
                </div>
            </div>
        </div>
        
        <!-- SECTION 2: THE FAMILY OF CONSTRUCTORS -->
        <div class="section">
            <h2>üìö 2. The Magical Book: A Family of Competing Constructors</h2>
            
            <div class="revision-highlight">
                <strong>KEY INSIGHT:</strong> The magical book is NOT a single constructor. It is a family of competing constructors, each implementing the same abstract task but via different internal construction. This is crucial to understanding the King's problem.
            </div>
            
            <div class="component selection">
                <div class="component-title">Multiple Constructors, Same Task</div>
                <div class="component-content">
                    <strong>Abstract task (shared by all):</strong><br>
                    <span class="notation">T_predict = {traveler_attributes(high-dim) ‚ü∂ risk_scalar(0-1)}</span><br><br>
                    
                    <strong>Constructor family:</strong><br>
                    ‚Ä¢ <strong>Constructor A (Adviser 1):</strong> Neural network with nonlinear activation<br>
                    ‚Ä¢ <strong>Constructor B (Adviser 2):</strong> Gradient boosting ensemble<br>
                    ‚Ä¢ <strong>Constructor C (Adviser 3):</strong> Linear model with regularization<br>
                    ‚Ä¢ More constructors from other advisers...<br><br>
                    
                    <strong>What Constructor Theory reveals:</strong><br>
                    Each constructor can perform the SAME task‚Äîtransforming attributes to risk‚Äîbut with fundamentally different properties:<br>
                    ‚Ä¢ <span class="highlight">Different error modes:</span> Each fails differently on out-of-distribution data<br>
                    ‚Ä¢ <span class="highlight">Different internal structure:</span> Nonlinear vs. linear vs. ensemble vs. tree-based<br>
                    ‚Ä¢ <span class="highlight">Different downstream implications:</span> Explainability, fairness, robustness<br><br>
                    
                    <strong>This is not about model selection in the traditional sense.</strong> It's about recognizing that multiple distinct constructors can implement the same abstract task, and the choice between them is not determined by the task alone‚Äîit requires an additional selection criterion.
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">What Prediction Does NOT Tell Us</div>
                <div class="component-content">
                    <strong>Any magical book can:</strong><br>
                    ‚úì Transform inputs to outputs accurately<br>
                    ‚úì Generalize to new travelers<br>
                    ‚úì Quantify prediction uncertainty<br><br>
                    
                    <strong>No magical book CANNOT (by itself):</strong><br>
                    ‚úó Distinguish signal from artifact<br>
                    ‚úó Identify which features matter<br>
                    ‚úó Explain why its decisions are made<br>
                    ‚úó Prove the rule is fair or justified<br><br>
                    
                    <strong>Constructor-theoretic meaning:</strong> Performing the prediction task does not make the explanation task possible. In fact, high-performing prediction models often become less interpretable‚Äîtheir success can obscure the underlying structure or introduce spurious correlations.
                </div>
            </div>
        </div>
        
        <!-- SECTION 3: THE ORDERING TASK -->
        <div class="section">
            <h2>üéØ 3. The Ordering Task: The Real Selection Criterion</h2>
            
            <div class="revision-highlight">
                <strong>KEY INSIGHT:</strong> The King's problem is not prediction. It is constructor selection via the ordering task. 
                The ordering task asks: "Which constructor most reliably ranks dangerous travelers above safe ones?" This is a different task from prediction itself.
            </div>
            
            <div class="component selection">
                <div class="component-title">What Is the Ordering Task?</div>
                <div class="component-content">
                    <strong>Formal specification:</strong><br>
                    <span class="notation">T_order = {constructor_family ‚ü∂ ranked_constructor (best ordering)}</span><br><br>
                    
                    <strong>Input substrate:</strong> Set of all competing constructors {A, B, C, ...}<br>
                    <strong>Output substrate:</strong> Single selected constructor with highest ordering robustness<br><br>
                    
                    <strong>What "ordering" means:</strong><br>
                    For any two travelers, where one is genuinely dangerous and one is genuinely safe, does the constructor assign a higher risk score to the dangerous traveler? How robustly does it do this across many pairs?<br><br>
                    
                    <strong>This is independent of:</strong><br>
                    ‚úó Absolute accuracy (whether risk scores are correctly calibrated)<br>
                    ‚úó Prediction of specific probability values<br>
                    ‚úó Explanation validity<br>
                    ‚úó Fairness properties<br><br>
                    
                    <strong>This is dependent on:</strong><br>
                    ‚úì Relative ranking of dangers<br>
                    ‚úì Robustness of ranking across repeated trials<br>
                    ‚úì Whether the constructor can distinguish high-risk from low-risk consistently
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">AUC: Quantifying the Ordering Task</div>
                <div class="component-content">
                    <strong>What AUC measures:</strong><br>
                    AUC (Area Under the Receiver Operating Characteristic curve) quantifies the probability that a constructor ranks a randomly chosen dangerous traveler higher than a randomly chosen safe traveler.<br><br>
                    
                    <span class="notation">AUC = P(risk_score(dangerous) > risk_score(safe))</span><br><br>
                    
                    <strong>Constructor-theoretic interpretation:</strong><br>
                    AUC measures how robustly the ordering task is possible. A higher AUC means the constructor's ordering task is more reliably possible across different samples of travelers.<br><br>
                    
                    <strong>Critical distinction:</strong> AUC is NOT about prediction accuracy. It's about whether the constructor maintains correct ordering. Two very different models could have the same AUC if they rank travelers in the same order, even if their probability estimates are calibrated differently.<br><br>
                    
                    <strong>Why AUC alone determines selection:</strong><br>
                    Because AUC directly measures the ordering task. Other metrics (accuracy, precision, recall, calibration) measure different properties and constrain understanding of weaknesses, but they do NOT measure whether a constructor can perform the ordering task robustly.
                </div>
            </div>
        </div>
        
        <!-- SECTION 4: OTHER METRICS -->
        <div class="section">
            <h2>üìä 4. Other Metrics: Understanding Failure Modes, Not Selection</h2>
            
            <div class="component">
                <div class="component-title">What Other Metrics Tell Us (And Don't Tell Us)</div>
                <div class="component-content">
                    <strong>Accuracy:</strong> Measures whether predictions match actual outcomes<br>
                    ‚Üí Constrains understanding of overall error rates<br>
                    ‚Üí Does NOT determine ordering robustness<br><br>
                    
                    <strong>Precision/Recall:</strong> Measures true positives and false positives at a fixed threshold<br>
                    ‚Üí Constrains understanding of trade-offs<br>
                    ‚Üí Does NOT measure ordering across all thresholds<br><br>
                    
                    <strong>Calibration:</strong> Measures whether predicted probabilities match actual frequencies<br>
                    ‚Üí Constrains understanding of probability validity<br>
                    ‚Üí Does NOT measure ordering (two constructors with same AUC but different calibration could both have valid orderings)<br><br>
                    
                    <strong>Fairness metrics (e.g., demographic parity):</strong> Measure whether decision rates are equal across groups<br>
                    ‚Üí Constrain understanding of group-level disparities<br>
                    ‚Üí Do NOT determine individual ordering robustness<br><br>
                    
                    <strong>Constructor-theoretic principle:</strong> These metrics constrain our understanding of a constructor's failure modes and weaknesses. They are essential for comprehensive assessment. But they do NOT perform the ordering task. They cannot replace AUC in determining which constructor to select for the prediction task.
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">Metrics as Constraint-Encoding Substrates</div>
                <div class="component-content">
                    Rather than thinking of metrics as alternative selection criteria, we should think of them as constraint-encoding substrates. Each metric reveals whether a constructor fails in a particular way:<br><br>
                    
                    ‚Ä¢ <strong>High AUC but low accuracy?</strong> Constructor ranks correctly but probability estimates are off<br>
                    ‚Ä¢ <strong>High AUC but low fairness?</strong> Constructor ranks correctly but disparately affects groups<br>
                    ‚Ä¢ <strong>High AUC but low calibration?</strong> Constructor ranks correctly but probability values are miscalibrated<br><br>
                    
                    These revelations are crucial for governance. But they come AFTER selection, not before. The selection itself is determined by AUC's performance on the ordering task.
                </div>
            </div>
        </div>

    <!-- SECTION 5: THE ADVISERS (FEATURE RANKING WITH PERTURBATION) -->
    <div class="section">
        <h2>üå≤ 5. The Advisers: Feature Ranking Constructors</h2>
        
        <div class="story-element">
            <strong>Story Element:</strong> The Forest Watcher looks for nonlinear patterns. The Straight-Line Scribe seeks linear relationships. 
            But unlike before, each adviser now produces not a single ranking, but a <em>distribution of rankings</em> across bootstrap perturbations. 
            This enables the Council of Methods to assess stability before inscribing features in the Book of Trusted Traits.
        </div>
        
        <div class="component neutral">
            <div class="component-title">Task Specification: Feature Ranking (with Perturbation)</div>
            <div class="component-content">
                <strong>Forest Watcher task (updated):</strong>
                <div class="notation">T_forest = {(attributes, bootstrap_b) ‚ü∂ ranked_features_b} for b = 1, 2, ..., B</div>
                <br>
                <strong>Straight-Line Scribe task (updated):</strong>
                <div class="notation">T_linear = {(attributes, bootstrap_b) ‚ü∂ ranked_features_b} for b = 1, 2, ..., B</div>
                <br>
                <strong>Key change from previous framework:</strong><br>
                Each adviser now produces <strong>B rankings</strong> (one per bootstrap sample, where B ‚â• 100), not a single ranking. 
                This enables stability assessment via SSUMP.<br><br>
                
                <strong>Input substrate:</strong> Full attribute space + bootstrap sample index b<br>
                <strong>Output substrate:</strong> Ranked list of features for that bootstrap sample<br><br>
                
                <strong>Perturbation types applied:</strong><br>
                ‚Ä¢ <strong>Bootstrap samples:</strong> Different random subsets of training data (B ‚â• 100)<br>
                ‚Ä¢ <strong>Hyperparameter variation:</strong> Small changes to model parameters (¬±10-20%)<br>
                ‚Ä¢ <strong>Random seed variation:</strong> Different initializations for stochastic components<br><br>
                
                <strong>Status: T_forest ‚úì, T_linear ‚úì (POSSIBLE)</strong><br>
                These ranking tasks are straightforwardly constructible. The challenge lies in aggregating their outputs stably‚Äîwhich is the Council's task.
            </div>
        </div>
        
        <div class="component">
            <div class="component-title">Why Two Methods Are Sufficient</div>
            <div class="component-content">
                <strong>The principle of methodological diversity:</strong><br>
                Two methods that are fundamentally different (linear vs. nonlinear) provide sufficient diversity to detect unstable features. 
                A feature that appears important only in one paradigm is likely capturing method-specific artifacts rather than true structure.<br><br>
                
                <strong>Why not more methods?</strong><br>
                ‚Ä¢ Additional methods add computational cost without proportional benefit<br>
                ‚Ä¢ Diminishing returns: if a feature survives linear + nonlinear scrutiny with stability across B perturbations, it's robust<br>
                ‚Ä¢ More methods require more complex aggregation rules, risking infinite regress<br><br>
                
                <strong>The two-method design is institutionally fixed</strong> as part of the governance framework's foundational architecture. 
                This prevents debates about "how many methods are enough" from blocking decision-making.
            </div>
        </div>
        
        <div class="component">
            <div class="component-title">Output to the Council of Methods</div>
            <div class="component-content">
                <strong>What each adviser submits to the Council:</strong><br><br>
                
                <strong>Forest Watcher submits:</strong><br>
                ‚Ä¢ B ranked lists of features (one per bootstrap sample)<br>
                ‚Ä¢ For each feature f: mean rank Œº_f and rank variance œÉ¬≤_f across B samples<br><br>
                
                <strong>Straight-Line Scribe submits:</strong><br>
                ‚Ä¢ B ranked lists of features (one per bootstrap sample)<br>
                ‚Ä¢ For each feature f: mean rank Œº_s and rank variance œÉ¬≤_s across B samples<br><br>
                
                <strong>The Council then:</strong><br>
                1. Applies Stability-Weighted Intersection to aggregate rankings<br>
                2. Runs the SSUMP test (Spearman's œÅ ‚â• 0.7 across perturbation pairs)<br>
                3. If SSUMP passes: inscribes stable features in the Book of Trusted Traits<br>
                4. If SSUMP fails: signals to Governance that feature selection is unstable ‚Üí ABSTAIN<br><br>
                
                <strong>Constructor-theoretic insight:</strong> The advisers no longer directly populate the Book of Trusted Traits. 
                They provide <em>evidence</em> (distributions of rankings) that the Council evaluates for stability. 
                This separation of ranking from aggregation enables principled stability verification.
            </div>
        </div>
    </div>       
        
        <!-- SECTION 6: THE BOOK OF TRUSTED TRAITS (CONSTRAINTS) -->
        <div class="section">
            <h2>üìò 6. The Book of Trusted Traits (Constraint Encoding)</h2>
            
            <div class="story-element">
                <strong>Story Element:</strong> This book records which features are allowed to participate in explanations. 
                It is not a passive record but a constraint that makes certain explanations impossible to construct.
            </div>
            
            <div class="component">
                <div class="component-title">Constraint as Making Tasks Impossible</div>
                <div class="component-content">
                    <strong>Crucial insight from Constructor Theory:</strong><br>
                    Unreliability is not punished after the fact. Instead, unreliable tasks are rendered unconstructible.<br><br>
                    
                    <strong>Formal statement:</strong><br>
                    If feature F is not in the Book of Trusted Traits, then:<br>
                    <div class="notation">T_explain_using_F = IMPOSSIBLE (‚úò)</div>
                    <br>
                    <strong>Why it's impossible:</strong> The constraint prevents the construction machinery (explanation constructor) from accessing that feature.<br><br>
                    
                    <strong>Advantages over post-hoc filtering:</strong><br>
                    ‚úì Prevents invalid explanations from being generated<br>
                    ‚úì Encodes reliability as a structural property, not a penalty<br>
                    ‚úì Makes the system design transparent<br>
                    ‚úì Forces the question: "Is this explanation even constructible?"
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">Constraint Propagation Downward</div>
                <div class="component-content">
                    <strong>How constraints flow through the system:</strong><br><br>
                    
                    <span style="display: block; margin: 10px 0;">
                    <strong>Level 0 (Institution):</strong> Book of Trusted Traits forbids unstable features<br>
                    ‚Üì<br>
                    <strong>Level 1 (Selection):</strong> Constructor selection determines which predictor to deploy<br>
                    ‚Üì<br>
                    <strong>Level 2 (Governance):</strong> Governance task only accepts decisions with trusted explanations<br>
                    ‚Üì<br>
                    <strong>Level 3 (Explanation):</strong> Explainer Lantern can only decompose using trusted features<br>
                    ‚Üì<br>
                    <strong>Level 4 (Subtasks):</strong> Feature stabilization produces the constraint<br>
                    </span>
                    
                    <strong>Result:</strong> The entire system is structured so that violations of trustworthiness become impossible, not just unlikely.
                </div>
            </div>
        </div>
        
        <!-- SECTION 7: THE EXPLAINER LANTERN -->
        <div class="section">
            <h2>üî¶ 7. The Explainer Lantern (Explanation Constructor - SHAP)</h2>
            
            <div class="story-element">
                <strong>Story Element:</strong> The lantern decomposes the risk prediction into contributions from each feature, 
                showing "how much" each attribute influenced the decision.
            </div>
            
            <div class="component fragile">
                <div class="component-title">Task Specification: Attribution/Explanation</div>
                <div class="component-content">
                    <strong>Formal notation:</strong>
                    <div class="notation">T_explain = {risk_prediction ‚ü∂ feature_attributions (SHAP values)}</div>
                    <br>
                    <strong>Input substrate:</strong> Prediction output (scalar risk value)<br>
                    <strong>Output substrate:</strong> Attribution vector showing contribution of each feature<br>
                    <strong>Constructor:</strong> SHAP (SHapley Additive exPlanations) or similar method<br><br>
                    
                    <strong>Status: T_explain ‚úì (POSSIBLE BUT FRAGILE)</strong><br>
                    The explanation task is technically possible‚Äîwe can always compute SHAP values‚Äîbut the question "Do these attributions track real structure?" is much harder to answer.<br><br>
                    
                    <strong>Critical ambiguity:</strong> The lantern always produces an attribution, regardless of whether it is meaningful. A decomposition is always constructible; what matters is whether it reflects genuine causal structure or arbitrary pattern.
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">The Fragility of Explanation</div>
                <div class="component-content">
                    <strong>Why explanations are fragile:</strong><br><br>
                    
                    1. <strong>Multiple valid decompositions:</strong> Different feature importance methods (SHAP, LIME, Integrated Gradients, etc.) can give different attributions for the same prediction.<br><br>
                    
                    2. <strong>Explanation without understanding:</strong> The lantern can decompose any function mathematically, but this decomposition may not correspond to the actual causal mechanisms the model uses.<br><br>
                    
                    3. <strong>Artifact vs. Signal:</strong> Features that appear important in the explanation might be spurious correlations or artifacts of the training data, not real drivers of risk.<br><br>
                    
                    <strong>Constructor-theoretic consequence:</strong> The existence of the explanation constructor (the lantern) does not guarantee that the explanation task is well-constrained. We need additional tests to determine whether the constructor is producing genuine explanations or merely plausible-sounding decompositions.
                </div>
            </div>
        </div>
        
        <!-- SECTION 8: THE TRIAL OF SANITY -->
        <div class="section">
            <h2>‚öñÔ∏è 8. The Trial of Sanity (Explanation Validation)</h2>
            
            <div class="story-element">
                <strong>Story Element:</strong> The trial deliberately destroys the model's learned structure and checks whether the 
                explanation continues to work unchanged. If it does, something is wrong‚Äîthe explanation is not tracking real structure.
            </div>
            
            <div class="component possible">
                <div class="component-title">Task Specification: Sanity Checking</div>
                <div class="component-content">
                    <strong>Formal notation:</strong>
                    <div class="notation">T_sanity = {(model, explanation) ‚ü∂ reliability_judgment}</div>
                    <br>
                    <strong>Procedure:</strong><br>
                    1. Train model M on real data ‚Üí produces explanation E<br>
                    2. Scramble labels (or permute features) ‚Üí train model M' ‚Üí produces explanation E'<br>
                    3. Compare: Does E ‚âà E'?<br>
                    4. If YES: Explanation is unreliable (does not depend on learned structure)<br>
                    5. If NO: Explanation may be meaningful (responds to structure)<br><br>
                    
                    <strong>Output metric:</strong> Sanity ratio = How much does explanation change when structure is removed?<br>
                    <div class="notation">Sanity_ratio = |explanation_real - explanation_scrambled| / |explanation_real|</div><br>
                    
                    <strong>Status: T_sanity ‚úì (POSSIBLE AND RIGOROUS)</strong><br>
                    This test is empirically feasible and provides real information about explanation reliability.
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">What Makes This Task Rigorous</div>
                <div class="component-content">
                    <strong>The sanity check transforms explanation from a possibility to a constraint:</strong><br><br>
                    
                    <strong>Before sanity check:</strong><br>
                    ‚Ä¢ Explanation is possible (T_explain ‚úì)<br>
                    ‚Ä¢ But we don't know if it's meaningful<br>
                    ‚Ä¢ Unreliability is not forbidden; it's just uncertain<br><br>
                    
                    <strong>After sanity check FAILS:</strong><br>
                    ‚Ä¢ Explanation is revealed as unreliable<br>
                    ‚Ä¢ This makes the governance task impossible<br>
                    ‚Ä¢ Consequence: T_explain becomes unreliable ‚Üí T_governance becomes impossible ‚Üí Abstain<br><br>
                    
                    <strong>After sanity check PASSES:</strong><br>
                    ‚Ä¢ We have evidence that explanation responds to structure<br>
                    ‚Ä¢ Governance task may proceed with increased confidence
                </div>
            </div>
        </div>
        
        <!-- SECTION 9: THE BOOK OF WHAT-IFS -->
        <div class="section">
            <h2>üåç 9. The Book of What-Ifs (Counterfactual Task)</h2>
            
            <div class="story-element">
                <strong>Story Element:</strong> This book shows how the traveler's state could be transformed to yield a different decision, 
                but only through transformations that are actually feasible.
            </div>
            
            <div class="component possible">
                <div class="component-title">Task Specification: Counterfactual Explanation</div>
                <div class="component-content">
                    <strong>Formal notation:</strong>
                    <div class="notation">T_counterfactual = {current_state ‚ü∂ nearby_state_with_different_outcome}</div>
                    <br>
                    <strong>Input substrate:</strong> Traveler's current attributes<br>
                    <strong>Output substrate:</strong> Modified attributes that would lead to different decision<br>
                    <strong>Constraint:</strong> Transformations must be feasible (physically, socially, institutionally possible)<br><br>
                    
                    <strong>Example:</strong><br>
                    ‚Ä¢ Current: Traveler rejected because of poor credit history<br>
                    ‚Ä¢ Counterfactual: "If credit score were 50 points higher, would be accepted"<br>
                    ‚Ä¢ This is actionable (the traveler can work to improve credit)<br><br>
                    
                    <strong>Example of FORBIDDEN counterfactual:</strong><br>
                    ‚Ä¢ "If you had been born in a different country, you'd be accepted"<br>
                    ‚Ä¢ This transformation is impossible (immutable attribute)<br>
                    ‚Ä¢ Constructor theory forbids this as a task because it's not constructible<br><br>
                    
                    <strong>Status: T_counterfactual ‚úì (POSSIBLE FOR FEASIBLE CHANGES, ‚úò FOR IMPOSSIBLE CHANGES)</strong>
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">Actionability and Feasibility Constraints</div>
                <div class="component-content">
                    <strong>Critical distinction:</strong> Not all counterfactuals are created equal.<br><br>
                    
                    <strong>Actionable counterfactuals:</strong><br>
                    ‚úì "Improve credit score" (possible through behavior change)<br>
                    ‚úì "Complete additional training" (possible through effort)<br>
                    ‚úì "Provide more recent references" (possible through obtaining documents)<br><br>
                    
                    <strong>Non-actionable counterfactuals:</strong><br>
                    ‚úò "Change your birthplace" (immutable)<br>
                    ‚úò "Change your age backwards" (impossible)<br>
                    ‚úò "Change your ethnicity" (immutable)<br><br>
                    
                    <strong>Constructor-theoretic principle:</strong> The counterfactual task can only generate transformations that are constructible. Attempting to construct impossible transformations violates the constraint that the task must be performable. This prevents the system from offering false or harmful advice.
                </div>
            </div>
        </div>
        
        <!-- SECTION 10: THE GOVERNANCE TASK (META-LEVEL) -->
        <div class="section">
            <h2>üëë 10. The Governance Task (Meta-Constructor)</h2>
            
            <div class="story-element">
                <strong>Story Element:</strong> The final decision layer does not decide directly on the traveler. 
                Instead, it decides whether decision-making itself is admissible at this moment.
            </div>
            
            <div class="component neutral">
                <div class="component-title">Task Specification: Governance Decision</div>
                <div class="component-content">
                    <strong>Formal notation:</strong>
                    <div class="notation">T_governance = {(prediction, explanation, sanity_check) ‚ü∂ decision_state (Accept, Review, Abstain)}</div>
                    <br>
                    <strong>Input substrates:</strong><br>
                    ‚Ä¢ Risk prediction from winning Magical Book (selected via AUC)<br>
                    ‚Ä¢ Attribution from Explainer Lantern<br>
                    ‚Ä¢ Sanity check results from Trial of Sanity<br>
                    ‚Ä¢ Institutional constraints from Book of Trusted Traits<br><br>
                    
                    <strong>Output substrate:</strong> Confidence judgment and decision action<br><br>
                    
                    <strong>Logic:</strong><br>
                    IF (prediction_is_reliable AND explanation_is_stable AND sanity_check_passes)<br>
                    &nbsp;&nbsp;&nbsp;&nbsp;THEN output: ACCEPT<br>
                    ELSE output: REVIEW or ABSTAIN<br><br>
                    
                    <strong>Crucial aspect:</strong> Abstention is not failure. It is the recognition that the explanation task is currently impossible given the available constructors and constraints.
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">Abstention as Principled Impossibility</div>
                <div class="component-content">
                    <strong>What abstention means:</strong><br><br>
                    <strong>NOT:</strong> "We don't have enough information yet" (epistemic uncertainty)<br>
                    <strong>RATHER:</strong> "The task of making a justified decision is currently impossible" (task impossibility)<br><br>
                    
                    <strong>When abstention is appropriate:</strong><br>
                    ‚Ä¢ Sanity check reveals explanation is not tracking real structure<br>
                    ‚Ä¢ Features used in explanation are not in the Book of Trusted Traits<br>
                    ‚Ä¢ Prediction confidence is below a threshold<br>
                    ‚Ä¢ Required constructors (explanation, stabilization) are not available<br><br>
                    
                    <strong>Constructor-theoretic principle:</strong> The governance task is to determine whether all enabling tasks are possible. If any required task becomes impossible (explanation fails sanity check, constraints are violated, constructors are unavailable), then the governance task outputs abstention. This is not a weakness; it's the correct output when justification is impossible.
                </div>
            </div>
        </div>
        
        <!-- SECTION 11: TASK HIERARCHY AND COMPOSITION -->
        <div class="section">
            <h2>üèóÔ∏è 11. Complete Task Hierarchy and Composition</h2>
            
            <div class="task-hierarchy">
                <div class="hierarchy-level">
                    <div class="hierarchy-level-title">META-LEVEL (Level 0): Institutional Constraints</div>
                    <div class="hierarchy-level-content">
                        <span class="notation">Constraint = {institutional_rules}</span><br>
                        The Book of Trusted Traits embodies institutional knowledge about which explanations are allowed.<br>
                        This constraint propagates downward to all other tasks.
                    </div>
                </div>
                
                <div class="hierarchy-level">
                    <div class="hierarchy-level-title">SELECTION LEVEL (Level 1): Constructor Selection Task</div>
                    <div class="hierarchy-level-content">
                        <span class="notation">T_select = {constructor_family ‚ü∂ best_constructor}</span><br>
                        Criterion: Ordering task robustness (AUC)<br>
                        Output: Selected constructor deployed at gate
                    </div>
                </div>
                
                <div class="hierarchy-level">
                    <div class="hierarchy-level-title">GOVERNANCE LEVEL (Level 2): Meta-Task</div>
                    <div class="hierarchy-level-content">
                        <span class="notation">T_governance = task_decision(admissibility)</span><br>
                        Takes all evidence from lower-level tasks and decides: Can we make a justified decision?<br>
                        Output: {Accept, Review, Abstain}
                    </div>
                </div>
                
                <div class="hierarchy-level">
                    <div class="hierarchy-level-title">DECISION LEVEL (Level 3): Three Parallel Tasks</div>
                    <div class="hierarchy-level-content">
                        <span class="notation">T_governance_inputs = T_predict ‚äó T_explain ‚äó T_sanity</span><br>
                        <br>
                        <strong>Parallel composition:</strong> These three tasks operate independently but feed into the governance decision.<br>
                        <strong>T_predict:</strong> Winning Magical Book produces risk score<br>
                        <strong>T_explain:</strong> Explainer Lantern produces attributions<br>
                        <strong>T_sanity:</strong> Trial of Sanity validates explanation reliability
                    </div>
                </div>
                
                <div class="hierarchy-level">
                    <div class="hierarchy-level-title">SUPPORTING LEVEL (Level 4): Subtasks and Constraints</div>
                    <div class="hierarchy-level-content">
                        <span class="notation">T_explain = T_stabilize ¬∑ T_constrain ¬∑ T_decompose</span><br>
                        <br>
                        <strong>Serial composition:</strong> These tasks form a pipeline.<br>
                        <strong>T_stabilize:</strong> Feature stabilization (Forest Watcher ‚äó Straight-Line Scribe)<br>
                        <strong>T_constrain:</strong> Constraint enforcement (Book of Trusted Traits)<br>
                        <strong>T_decompose:</strong> Attribution calculation (SHAP decomposition)
                    </div>
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">Composition Principle</div>
                <div class="component-content">
                    <strong>Key insight from Constructor Theory:</strong><br>
                    If all component tasks are possible and properly constrained, the composed task is possible.<br><br>
                    
                    <strong>For governance to be possible:</strong><br>
                    ‚úì Constructor selection must succeed (T_select ‚úì)<br>
                    ‚úì Prediction must be possible (T_predict ‚úì)<br>
                    ‚úì Explanation must be possible (T_explain ‚úì)<br>
                    ‚úì Stabilization must be possible (T_stabilize ‚úì)<br>
                    ‚úì Sanity check must pass<br><br>
                    
                    <strong>If any component becomes impossible:</strong><br>
                    ‚úò The entire governance task becomes impossible<br>
                    ‚Üí Output: ABSTAIN<br><br>
                    
                    This is not weakness but strength: the system correctly identifies when justified decision-making is impossible and refuses to proceed.
                </div>
            </div>
        </div>
        
        <!-- SECTION 12: KEY TRANSFORMATIONS TABLE -->
        <div class="section">
            <h2>üìä 12. Summary Table: All Tasks in the System</h2>
            
            <table>
                <thead>
                    <tr>
                        <th>Task Name</th>
                        <th>Input</th>
                        <th>Output</th>
                        <th>Constructor</th>
                        <th>Status</th>
                        <th>Key Challenge</th>
                    </tr>
                </thead>
                <tbody>
                    <tr>
                        <td><strong>Constructor Selection</strong></td>
                        <td>All candidate constructors</td>
                        <td>Best constructor (AUC-ranked)</td>
                        <td>King's decision process</td>
                        <td>‚úì Possible</td>
                        <td>Which constructor ranks dangers most robustly?</td>
                    </tr>
                    <tr>
                        <td><strong>Ordering</strong></td>
                        <td>Constructor's risk scores</td>
                        <td>Ranking of travelers by danger</td>
                        <td>Selected constructor</td>
                        <td>‚úì Possible</td>
                        <td>AUC: P(dangerous ranked higher)</td>
                    </tr>
                    <tr>
                        <td><strong>Prediction</strong></td>
                        <td>Traveler attributes (high-dim)</td>
                        <td>Risk scalar (0-1)</td>
                        <td>Winning Magical Book</td>
                        <td>‚úì Possible</td>
                        <td>May capture artifacts, not true risk</td>
                    </tr>
                    <tr>
                        <td><strong>Explanation</strong></td>
                        <td>Risk prediction</td>
                        <td>Feature attributions</td>
                        <td>Explainer Lantern (SHAP)</td>
                        <td>‚úì Possible but Fragile</td>
                        <td>Multiple valid decompositions; unclear if meaningful</td>
                    </tr>
                    <tr>
                        <td><strong>Stabilization</strong></td>
                        <td>Attributes</td>
                        <td>Stable feature subset</td>
                        <td>Forest Watcher ‚äó Straight-Line Scribe</td>
                        <td>‚úì Possible</td>
                        <td>Which methods to combine?</td>
                    </tr>
                    <tr>
                        <td><strong>Constraint Encoding</strong></td>
                        <td>Stable features</td>
                        <td>Trusted traits registry</td>
                        <td>Book of Trusted Traits</td>
                        <td>‚úì Possible</td>
                        <td>Enforcing constraints in practice</td>
                    </tr>
                    <tr>
                        <td><strong>Sanity Check</strong></td>
                        <td>Model + Explanation</td>
                        <td>Reliability judgment</td>
                        <td>Trial of Sanity</td>
                        <td>‚úì Possible and Rigorous</td>
                        <td>Interpretation of sanity ratio</td>
                    </tr>
                    <tr>
                        <td><strong>Counterfactual</strong></td>
                        <td>Current state</td>
                        <td>Alternative states (feasible only)</td>
                        <td>Book of What-Ifs</td>
                        <td>‚úì Possible (constrained)</td>
                        <td>Defining feasibility boundary</td>
                    </tr>
                    <tr>
                        <td><strong>Governance</strong></td>
                        <td>All evidence (prediction, explanation, sanity)</td>
                        <td>Decision (Accept/Review/Abstain)</td>
                        <td>Meta-constructor</td>
                        <td>‚úì if enabled, ‚úò if any fails</td>
                        <td>Justified abstention when components fail</td>
                    </tr>
                </tbody>
            </table>
        </div>
        
        <!-- SECTION 13: CENTRAL PRINCIPLE -->
        <div class="section">
            <h2>‚≠ê 13. Central Principles</h2>
            
            <div class="key-principle">
                <strong>Principle 1: Explanation is a Separate Task</strong><br><br>
                Explanation is not a decoration on prediction. It is a <span class="highlight">separate task whose possibility must be demonstrated separately</span>. 
                Performing the prediction task does not automatically make the explanation task possible. In fact, the more complex and successful a prediction model becomes, 
                the harder it may be to construct valid explanations for its outputs.<br><br>
                
                <strong>Traditional view (WRONG):</strong><br>
                Prediction ‚üπ Explanation ‚üπ Better prediction + Better understanding<br><br>
                
                <strong>Constructor theory view (CORRECT):</strong><br>
                Prediction is possible (T_predict ‚úì)<br>
                Explanation might be possible (T_explain ?) depends on additional constraints<br>
                Reliable explanation is more demanding (requires T_stabilize, T_constrain, T_sanity)<br>
                Governance requires all enabling tasks to be possible (T_governance ?)
            </div>
            
            <div class="key-principle">
                <strong>Principle 2: Constructor Selection ‚â† Prediction</strong><br><br>
                The King does not need to find the best prediction constructor. He needs to solve the constructor-selection task. 
                These are not the same thing.<br><br>
                
                <strong>Constructor Selection Task:</strong> Which constructor most robustly implements the ordering task?<br>
                <strong>Answer via:</strong> AUC (Area Under ROC Curve)<br><br>
                
                <strong>This is different from:</strong><br>
                ‚Ä¢ Finding the constructor with best calibration<br>
                ‚Ä¢ Finding the constructor that minimizes false positives<br>
                ‚Ä¢ Finding the constructor with best fairness properties<br><br>
                
                <strong>Why this distinction matters:</strong><br>
                The ordering task is specifically about ranking‚Äîwhich constructor reliably distinguishes dangerous from safe? Other metrics measure different things. They constrain understanding of failure modes but do not perform the selection task.
            </div>
            
            <div class="component">
                <div class="component-title">When Explanation Becomes Impossible</div>
                <div class="component-content">
                    <strong>Scenario 1: Model captures spurious correlation</strong><br>
                    ‚Ä¢ Magical Book learns: "Red travelers are riskier" (artifact of training data)<br>
                    ‚Ä¢ Explainer Lantern identifies "Red-ness" as important feature<br>
                    ‚Ä¢ Sanity check: Scramble labels, model no longer learns this pattern<br>
                    ‚Ä¢ Result: Explanation depends on artifact, not real structure<br>
                    ‚Ä¢ Consequence: T_explain becomes unreliable ‚Üí governance becomes impossible ‚Üí abstain<br><br>
                    
                    <strong>Scenario 2: Feature violates fairness constraint</strong><br>
                    ‚Ä¢ Magical Book learns: "Ethnicity" predicts risk<br>
                    ‚Ä¢ Explainer Lantern attributes high importance to ethnicity<br>
                    ‚Ä¢ Book of Trusted Traits forbids ethnicity as legitimate feature<br>
                    ‚Ä¢ Result: Explanation cannot be constructed using trusted features only<br>
                    ‚Ä¢ Consequence: T_explain becomes impossible (by constraint) ‚Üí governance becomes impossible ‚Üí abstain<br><br>
                    
                    <strong>Scenario 3: Explanation changes under different methods</strong><br>
                    ‚Ä¢ Forest Watcher: "Age matters most"<br>
                    ‚Ä¢ Straight-Line Scribe: "Income matters most"<br>
                    ‚Ä¢ Neither feature stabilizes<br>
                    ‚Ä¢ Result: No robust explanation available<br>
                    ‚Ä¢ Consequence: T_stabilize fails ‚Üí cannot build T_explain ‚Üí governance becomes impossible ‚Üí abstain
                </div>
            </div>
        </div>
        
        <!-- SECTION 14: COMPARISON WITH NAIVE APPROACH -->
        <div class="section">
            <h2>üîÑ 14. Constructor Theory vs. Traditional Approach</h2>
            
            <div class="comparison-grid">
                <div class="comparison-card">
                    <h4>Traditional ML View</h4>
                    <ul>
                        <li><strong>Prediction:</strong> Find the "best model" ‚úì</li>
                        <li><strong>Selection:</strong> Optimize accuracy/AUC</li>
                        <li><strong>Explanation:</strong> Apply SHAP ‚úì</li>
                        <li><strong>Validation:</strong> Report feature importances</li>
                        <li><strong>Decision:</strong> If prediction confident, decide</li>
                        <li><strong>Problem:</strong> No test of whether explanation tracks real structure</li>
                        <li><strong>Assumption:</strong> High accuracy = valid explanations</li>
                        <li><strong>Risk:</strong> Can confidently make unjustified decisions</li>
                    </ul>
                </div>
                
                <div class="comparison-card">
                    <h4>Constructor Theory Approach</h4>
                    <ul>
                        <li><strong>Prediction:</strong> Select constructor via ordering task (AUC)</li>
                        <li><strong>Selection:</strong> AUC measures constructor robustness for selection</li>
                        <li><strong>Explanation:</strong> Compute SHAP, but mark task T_explain as ?</li>
                        <li><strong>Validation:</strong> Stabilize features independently, run sanity checks</li>
                        <li><strong>Decision:</strong> Only if ALL enabling tasks are verified possible</li>
                        <li><strong>Advantage:</strong> Tests whether explanation is constructible</li>
                        <li><strong>Recognition:</strong> Prediction reliability ‚â† explanation validity</li>
                        <li><strong>Safety:</strong> Principled abstention when justification is impossible</li>
                    </ul>
                </div>
            </div>
            
            <div class="component">
                <div class="component-title">Why Constructor Theory is Superior</div>
                <div class="component-content">
                    <strong>The transformation:</strong> From asking "Can we predict?" to asking "Can we justify?"<br><br>
                    
                    <strong>Naive approach assumes:</strong> High accuracy ‚üπ Explanation is valid<br>
                    <strong>Constructor theory recognizes:</strong> High accuracy ‚â† Valid explanation (they are different tasks)<br><br>
                    
                    <strong>Practical advantage:</strong> When the sanity check fails, the system doesn't produce a false sense of certainty. Instead, it correctly identifies that the explanation task is unreliable and abstains from decision-making. This prevents unjustified harms.
                </div>
            </div>
        </div>
        
        <!-- SECTION 15: VISUAL STORY FLOW -->
        <div class="section">
            <h2>üìñ 15. The Story Flow: From Traveler to Decision</h2>
            
            <div class="flow-diagram">
                <div style="text-align: center; margin: 20px 0;">
                    <div class="flow-box selection">üìö Family of Magical Books</div>
                    <div class="flow-arrow">‚Üí</div>
                    <div class="flow-box decision">üéØ Ordering Task (AUC)</div>
                    <div class="flow-arrow">‚Üí</div>
                    <div class="flow-box input">üèÜ Winning Constructor</div>
                </div>
                
                <div style="text-align: center; margin: 20px 0;">
                    <div class="flow-box input">üö∂ Traveler Arrives</div>
                    <div class="flow-arrow">‚Üí</div>
                    <div class="flow-box secondary">üìñ Winning Book (Predict)</div>
                    <div class="flow-arrow">‚Üí</div>
                    <div class="flow-box secondary">üî¶ Explainer Lantern (Explain)</div>
                </div>
                
                <div style="text-align: center; margin: 20px 0;">
                    <div class="flow-box secondary">üå≤ Forest Watcher + üìù Scribe (Stabilize)</div>
                    <div class="flow-arrow">‚Üì</div>
                    <div class="flow-box secondary">üìö Book of Trusted Traits (Constrain)</div>
                </div>
                
                <div style="text-align: center; margin: 20px 0;">
                    <div class="flow-box">‚öñÔ∏è Trial of Sanity (Test)</div>
                    <div class="flow-arrow">‚Üí</div>
                    <div class="flow-box decision">üëë Governance (Decide Admissibility)</div>
                </div>
                
                <div style="text-align: center; margin: 20px 0; padding: 15px; background: #f5f5f5; border-radius: 6px;">
                    <strong>IF all tasks are possible:</strong><br>
                    <div class="flow-box decision" style="margin-top: 10px;">‚úÖ Accept Decision</div><br>
                    
                    <strong>ELSE IF some tasks are impossible:</strong><br>
                    <div class="flow-box" style="background: linear-gradient(135deg, #ff9800 0%, #f57c00 100%); color: white; margin-top: 10px;">‚ö†Ô∏è Review / üõë Abstain</div>
                </div>
            </div>
        </div>
        
        <!-- SECTION 16: CONCLUSION -->
        <div class="section" style="background: linear-gradient(135deg, #e3f2fd 0%, #f3e5f5 100%); border-left-color: #0d47a1;">
            <h2>‚ú® Conclusion: The Architecture of Justified Decision-Making</h2>
            
            <div class="key-insight" style="border-color: #0d47a1; background: white;">
                <strong>From the Constructor Theory perspective:</strong><br><br>
                
                The story of the kingdom gate is not a fable about tools and their limitations. It is a demonstration that 
                <span class="highlight">justified decision-making is a complex task with multiple enabling subtasks</span>. 
                Each subtask‚Äîconstructor selection, prediction, explanation, stabilization, constraint enforcement, sanity checking, counterfactual generation‚Äî
                is itself a task whose possibility must be independently verified.<br><br>
                
                <strong>The System Works Because:</strong><br>
                1. <strong>Constructor selection precedes deployment:</strong> AUC determines which constructor most robustly orders dangers<br>
                2. <strong>Constraints flow downward:</strong> Institutional rules (Book of Trusted Traits) structure what lower-level tasks can perform<br>
                3. <strong>Tasks compose hierarchically:</strong> Simple tasks (prediction) enable complex tasks (explanation), which enable meta-tasks (governance)<br>
                4. <strong>Verification is rigorous:</strong> The sanity check reveals when explanations fail to track real structure<br>
                5. <strong>Abstention is principled:</strong> When any enabling task becomes impossible, the governance task correctly outputs "do not decide"<br><br>
                
                <strong>The Final Insight:</strong><br>
                AUC determines which constructor to select. But AUC says nothing about explanation validity. Where explanation is unreliable, the correct outcome is not a weaker story or a cautious decision. 
                The correct outcome is the <span class="highlight">principled impossibility of confident judgment</span>. 
                Constructor theory formalizes this: a task that cannot be constructed simply <span class="highlight">cannot be performed</span>.
            </div>
        </div>
    </div>
</body>
</html>
